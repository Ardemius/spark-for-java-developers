= Apache Spark for Java developers
Thomas SCHWENDER <https://github.com/ardemius[@ardemius]>
// Handling GitHub admonition blocks icons
ifndef::env-github[:icons: font]
ifdef::env-github[]
:status:
:outfilesuffix: .adoc
:caution-caption: :fire:
:important-caption: :exclamation:
:note-caption: :paperclip:
:tip-caption: :bulb:
:warning-caption: :warning:
endif::[]
:imagesdir: ./images
:source-highlighter: highlightjs
// Next 2 ones are to handle line breaks in some particular elements (list, footnotes, etc.)
:lb: pass:[<br> +]
:sb: pass:[<br>]
// check https://github.com/Ardemius/personal-wiki/wiki/AsciiDoctor-tips for tips on table of content in GitHub
:toc: macro
:toclevels: 2
// To turn off figure caption labels and numbers
:figure-caption!:

toc::[]

Udemy training : https://www.udemy.com/course/apache-spark-for-java-developers

== 1.3 - Introduction

*Hadoop* est un modèle rigide : on fait obligatoirement 1 *map* suivi d'1 *reduce*, et, à la fin de cet enchaînement, le tout est obligatoirement écrit sur disque. +
En comparaison, Spark propose plus de 80 high-level operators, à la place des 2 seuls map et reduce.

Avec Spark, en *standalone mode* (single computer), même pour de petits datasets, on bénéficie totalement du *multi-core parallel processing* (le multi-threading est géré par Spark, pas besoin de le gérer soi-même en Java, ce qui est toujours considéré comme compliqué). +
-> Pas besoin de se trouver dans des conditions "Big Data" pour trouver un intérêt à Spark.

== 1.4 - Spark architecture and RDDs

* A *partition* is a *block of data*, NOT a node.
* A *task* : a function executing against a partition
* *RDD* : Resilient Distributed Dataset
* The Spark *DAG* is an *execution plan*

== 2 - Getting Started

.Spark doesn't work with Java 9
[NOTE]
====
Please note at the time of writing (November 2018), Spark does not support Java 9 onwards. +
This is due to their internal use of a class called sun.misc.Unsafe which has been removed from Java 9.
====

